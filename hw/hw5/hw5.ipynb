{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 5: Evaluation metrics\n",
    "### Associated lectures: Lectures 9, 10 \n",
    "\n",
    "**Due date: Tuesday, June 07, 2022 at 18:00**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tests_hw5\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:3}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2022s/blob/master/docs/homework_instructions.md).\n",
    "\n",
    "**You may work with a partner on this homework and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 2. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Precision, recall, and f1 score by hand <a name=\"1\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the problem of predicting whether a patient has a disease or not. Below are confusion matrices of two machine learning models: Model A and Model B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model A confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted disease</th>\n",
       "      <th>Predicted no disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual disease</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual no disease</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted disease  Predicted no disease\n",
       "Actual disease                     3                    10\n",
       "Actual no disease                  1                   106"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_A = pd.DataFrame(\n",
    "    [[3, 10],\n",
    "     [1, 106]],\n",
    "    columns=[\"Predicted disease\", \"Predicted no disease\"],\n",
    "    index=[\"Actual disease\", \"Actual no disease\"])\n",
    "\n",
    "cm_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model B confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted disease</th>\n",
       "      <th>Predicted no disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual disease</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual no disease</th>\n",
       "      <td>12</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted disease  Predicted no disease\n",
       "Actual disease                     8                     5\n",
       "Actual no disease                 12                    95"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_B = pd.DataFrame(\n",
    "    [[8, 5],\n",
    "     [12, 95]],\n",
    "    columns=[\"Predicted disease\", \"Predicted no disease\"],\n",
    "    index=[\"Actual disease\", \"Actual no disease\"])\n",
    "\n",
    "cm_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Positive vs. negative class \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Precision, recall, and f1 score depend upon which class is considered \"positive\", that is the thing you wish to find. In the example above, which class is likely to be the \"positive\" class? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Disease' is likely to be the positive class. We are most likely interested in detecting diseases, not detecting healthy people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Accuracy\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Calculate accuracies for Model A and Model B. \n",
    "\n",
    "We'll store all metrics associated with Model A and Model B in the `results_dict` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\"A\": {}, \"B\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"accuracy\"] = np.diag(cm_A).sum() / cm_A.sum().sum()\n",
    "results_dict[\"B\"][\"accuracy\"] = np.diag(cm_B).sum() / cm_B.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_2_1(\n",
    "    results_dict[\"A\"][\"accuracy\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_2_2(\n",
    "    results_dict[\"B\"][\"accuracy\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.858333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 A         B\n",
       "accuracy  0.908333  0.858333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Which model would you pick? \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Which model would you pick simply based on the accuracy metric? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. It has a higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Precision, recall, f1-score\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Calculate precision, recall, f1-score for Model A and Model B manually, without calling `scikit-learn` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"precision\"] = cm_A.iloc[0,0]/(cm_A.iloc[0,0] + cm_A.iloc[1,0])\n",
    "results_dict[\"B\"][\"precision\"] = cm_B.iloc[0,0]/(cm_B.iloc[0,0] + cm_B.iloc[1,0])\n",
    "results_dict[\"A\"][\"recall\"] = cm_A.iloc[0,0]/(cm_A.iloc[0,0] + cm_A.iloc[0,1])\n",
    "results_dict[\"B\"][\"recall\"] = cm_B.iloc[0,0]/(cm_B.iloc[0,0] + cm_B.iloc[0,1])\n",
    "results_dict[\"A\"][\"f1\"] = 2 * results_dict[\"A\"][\"precision\"] * results_dict[\"A\"][\"recall\"] / (results_dict[\"A\"][\"precision\"] + results_dict[\"A\"][\"recall\"])\n",
    "results_dict[\"B\"][\"f1\"] = 2 * results_dict[\"B\"][\"precision\"] * results_dict[\"B\"][\"recall\"] / (results_dict[\"B\"][\"precision\"] + results_dict[\"B\"][\"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_1(\n",
    "    results_dict[\"A\"][\"precision\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_2(\n",
    "    results_dict[\"B\"][\"precision\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_3(\n",
    "    results_dict[\"A\"][\"recall\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_4(\n",
    "    results_dict[\"B\"][\"recall\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_5(\n",
    "    results_dict[\"A\"][\"f1\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_6(\n",
    "    results_dict[\"B\"][\"f1\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the dataframe with all results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.858333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A         B\n",
       "accuracy   0.908333  0.858333\n",
       "precision  0.750000  0.400000\n",
       "recall     0.230769  0.615385\n",
       "f1         0.352941  0.484848"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Discussion\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Which metric is more informative in this problem? Why? \n",
    "2. Which model would you pick based on this information? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  *Recall* is the most important when it comes to disease diagnosis because of how devastating a false negative can be for patient health.\n",
    "2. *Model B* is better for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 1.6 \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Provide 4 to 5 example classification datasets (with links) where accuracy metric would be misleading. Discuss which evaluation metric would be more appropriate for each dataset. You may consider datasets we have used in this course so far. You could also look up datasets on Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For lung cancer diagnosis https://www.kaggle.com/datasets/mysarahmadbhat/lung-cancer, recall is more important.\n",
    "\n",
    "For predicting top hits on Spotify https://www.kaggle.com/datasets/paradisejoy/top-hits-spotify-from-20002019, precision is more important if a company is to search for a musician to sign. The dataset is imbalancedm and high accuracy can be achieved with a dummy classifier in this case, but a company would likely want high precision because they don't want to waste time with false positives.\n",
    "\n",
    "For scam detection https://www.kaggle.com/datasets/amruthjithrajvr/recruitment-scam, recall is more important because false negatives can cause a lot of financial damage.\n",
    "\n",
    "When buying a used car https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data, recall is more important to detect potential lemon cars that are worth significantly less than how they appear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Classification evaluation metrics using `sklearn` <a name=\"2\"></a>\n",
    "<hr>\n",
    "\n",
    "In general, when a dataset is imbalanced, accuracy does not provide the whole story. In class, we looked at credit card fraud dataset which is a classic example of an imbalanced dataset. \n",
    "\n",
    "Another example is customer churn datasets. [Customer churn](https://en.wikipedia.org/wiki/Customer_attrition) refers to the notion of customers leaving a subscription service like Netflix. In this exercise, we will try to predict customer churn in a dataset where most of the customers stay with the service and a small minority cancel their subscription. To start, please download the [Kaggle telecom customer churn dataset](https://www.kaggle.com/becksddf/churn-in-telecoms-dataset). Once you have the data, you should be able to run the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starter code below reads the data CSV as a pandas dataframe and splits it into 70% train and 30% test. \n",
    "\n",
    "Note that `churn` column in the dataset is the target. \"True\" means the customer left the subscription (churned) and \"False\" means they stayed.\n",
    "\n",
    "> Note that for this kind of problem a more appropriate technique is something called survival analysis and we'll be talking about it later in the course. For now, we'll just treat it as a binary classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>NE</td>\n",
       "      <td>70</td>\n",
       "      <td>415</td>\n",
       "      <td>421-8535</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>213.4</td>\n",
       "      <td>86</td>\n",
       "      <td>36.28</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>17.40</td>\n",
       "      <td>256.6</td>\n",
       "      <td>101</td>\n",
       "      <td>11.55</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>WI</td>\n",
       "      <td>67</td>\n",
       "      <td>510</td>\n",
       "      <td>417-2265</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>109.1</td>\n",
       "      <td>134</td>\n",
       "      <td>18.55</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>12.10</td>\n",
       "      <td>91.2</td>\n",
       "      <td>86</td>\n",
       "      <td>4.10</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>NJ</td>\n",
       "      <td>122</td>\n",
       "      <td>415</td>\n",
       "      <td>327-9341</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>34</td>\n",
       "      <td>146.4</td>\n",
       "      <td>104</td>\n",
       "      <td>24.89</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>7.62</td>\n",
       "      <td>220.0</td>\n",
       "      <td>91</td>\n",
       "      <td>9.90</td>\n",
       "      <td>15.6</td>\n",
       "      <td>4</td>\n",
       "      <td>4.21</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>NV</td>\n",
       "      <td>107</td>\n",
       "      <td>510</td>\n",
       "      <td>419-9688</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>234.1</td>\n",
       "      <td>91</td>\n",
       "      <td>39.80</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>13.86</td>\n",
       "      <td>282.5</td>\n",
       "      <td>100</td>\n",
       "      <td>12.71</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>HI</td>\n",
       "      <td>105</td>\n",
       "      <td>510</td>\n",
       "      <td>364-8128</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>125.4</td>\n",
       "      <td>116</td>\n",
       "      <td>21.32</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>22.23</td>\n",
       "      <td>241.6</td>\n",
       "      <td>104</td>\n",
       "      <td>10.87</td>\n",
       "      <td>11.4</td>\n",
       "      <td>9</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>WY</td>\n",
       "      <td>126</td>\n",
       "      <td>408</td>\n",
       "      <td>339-9798</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>197.6</td>\n",
       "      <td>126</td>\n",
       "      <td>33.59</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>20.95</td>\n",
       "      <td>285.3</td>\n",
       "      <td>104</td>\n",
       "      <td>12.84</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>WV</td>\n",
       "      <td>70</td>\n",
       "      <td>510</td>\n",
       "      <td>348-3777</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>143.4</td>\n",
       "      <td>72</td>\n",
       "      <td>24.38</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>14.45</td>\n",
       "      <td>127.9</td>\n",
       "      <td>68</td>\n",
       "      <td>5.76</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>NJ</td>\n",
       "      <td>125</td>\n",
       "      <td>415</td>\n",
       "      <td>406-6400</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>182.3</td>\n",
       "      <td>64</td>\n",
       "      <td>30.99</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>11.88</td>\n",
       "      <td>171.6</td>\n",
       "      <td>96</td>\n",
       "      <td>7.72</td>\n",
       "      <td>11.6</td>\n",
       "      <td>7</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>NE</td>\n",
       "      <td>159</td>\n",
       "      <td>415</td>\n",
       "      <td>362-5111</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>189.1</td>\n",
       "      <td>105</td>\n",
       "      <td>32.15</td>\n",
       "      <td>...</td>\n",
       "      <td>147</td>\n",
       "      <td>20.92</td>\n",
       "      <td>242.0</td>\n",
       "      <td>106</td>\n",
       "      <td>10.89</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>PA</td>\n",
       "      <td>106</td>\n",
       "      <td>408</td>\n",
       "      <td>403-9167</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>133.7</td>\n",
       "      <td>45</td>\n",
       "      <td>22.73</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>15.96</td>\n",
       "      <td>181.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.19</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2333 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  account length  area code phone number international plan  \\\n",
       "1402    NE              70        415     421-8535                 no   \n",
       "1855    WI              67        510     417-2265                 no   \n",
       "633     NJ             122        415     327-9341                 no   \n",
       "1483    NV             107        510     419-9688                yes   \n",
       "2638    HI             105        510     364-8128                 no   \n",
       "...    ...             ...        ...          ...                ...   \n",
       "2154    WY             126        408     339-9798                yes   \n",
       "3089    WV              70        510     348-3777                 no   \n",
       "1766    NJ             125        415     406-6400                 no   \n",
       "1122    NE             159        415     362-5111                 no   \n",
       "1346    PA             106        408     403-9167                yes   \n",
       "\n",
       "     voice mail plan  number vmail messages  total day minutes  \\\n",
       "1402              no                      0              213.4   \n",
       "1855              no                      0              109.1   \n",
       "633              yes                     34              146.4   \n",
       "1483              no                      0              234.1   \n",
       "2638              no                      0              125.4   \n",
       "...              ...                    ...                ...   \n",
       "2154              no                      0              197.6   \n",
       "3089             yes                     30              143.4   \n",
       "1766              no                      0              182.3   \n",
       "1122              no                      0              189.1   \n",
       "1346              no                      0              133.7   \n",
       "\n",
       "      total day calls  total day charge  ...  total eve calls  \\\n",
       "1402               86             36.28  ...               77   \n",
       "1855              134             18.55  ...               76   \n",
       "633               104             24.89  ...              103   \n",
       "1483               91             39.80  ...              105   \n",
       "2638              116             21.32  ...               95   \n",
       "...               ...               ...  ...              ...   \n",
       "2154              126             33.59  ...              112   \n",
       "3089               72             24.38  ...               92   \n",
       "1766               64             30.99  ...              121   \n",
       "1122              105             32.15  ...              147   \n",
       "1346               45             22.73  ...              107   \n",
       "\n",
       "      total eve charge  total night minutes  total night calls  \\\n",
       "1402             17.40                256.6                101   \n",
       "1855             12.10                 91.2                 86   \n",
       "633               7.62                220.0                 91   \n",
       "1483             13.86                282.5                100   \n",
       "2638             22.23                241.6                104   \n",
       "...                ...                  ...                ...   \n",
       "2154             20.95                285.3                104   \n",
       "3089             14.45                127.9                 68   \n",
       "1766             11.88                171.6                 96   \n",
       "1122             20.92                242.0                106   \n",
       "1346             15.96                181.9                 89   \n",
       "\n",
       "      total night charge  total intl minutes  total intl calls  \\\n",
       "1402               11.55                 5.7                 4   \n",
       "1855                4.10                10.9                 5   \n",
       "633                 9.90                15.6                 4   \n",
       "1483               12.71                10.0                 3   \n",
       "2638               10.87                11.4                 9   \n",
       "...                  ...                 ...               ...   \n",
       "2154               12.84                12.5                 8   \n",
       "3089                5.76                 9.4                 4   \n",
       "1766                7.72                11.6                 7   \n",
       "1122               10.89                10.4                 5   \n",
       "1346                8.19                10.7                 2   \n",
       "\n",
       "      total intl charge  customer service calls  churn  \n",
       "1402               1.54                       1  False  \n",
       "1855               2.94                       2  False  \n",
       "633                4.21                       2  False  \n",
       "1483               2.70                       1  False  \n",
       "2638               3.08                       2  False  \n",
       "...                 ...                     ...    ...  \n",
       "2154               3.38                       2  False  \n",
       "3089               2.54                       3  False  \n",
       "1766               3.13                       2  False  \n",
       "1122               2.81                       1   True  \n",
       "1346               2.89                       1   True  \n",
       "\n",
       "[2333 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bigml_59c28831336c6604c800002a.csv\", encoding=\"utf-8\")\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=123)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Distribution of target values\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Examine the distribution of target values in the train split. Do you see class imbalance? If yes, do we need to deal with it? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.850407\n",
       "True     0.149593\n",
       "Name: churn, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['churn'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1984\n",
       "True      349\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a class imbalance. More than 85% of the customers stayed. But there are still 349 customers who left in the dataset, and that might be enough to prevent overfitting. But the imbalance undermines the validity of accuracy as a model evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (Optional) 2.2 EDA \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Come up with **two** exploratory questions you would like to answer and explore those. Briefly discuss your results in 1-3 sentences.\n",
    "\n",
    "You are welcome to use `pandas_profiling` (see Lecture 10) but you don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport\n",
    "# profile = ProfileReport(train_df, title=\"Pandas Profiling Report\")\n",
    "# profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are people who use the phone service for longer during the day more likely to stay? The correlation (Pearson's r) is moderate between total day minutes and churn. It is not good enough a predictor for churn, but it does seem to indicate people who use the service more tend to leave. Maybe because they use the phone service for work.**\n",
    "\n",
    "**Are people who use the customer service more likely to leave? Phik indicates there is a high correlation. Maybe people tend to leave after using customer service calls because they leave the service through customer service calls, and when their problems are not resolved through customer service.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Column transformer \n",
    "rubric={points:10}\n",
    "\n",
    "The code below creates `X_train`, `y_train`, `X_test`, `y_test` for you. \n",
    "In preparation for building a classifier, set up a `ColumnTransformer` that performs whatever feature transformations you deem sensible. This can include dropping features if you think they are not helpful. Remember that by default `ColumnTransformer` will drop any columns that aren't accounted for when it's created.\n",
    "\n",
    "In each case, briefly explain your rationale with 1-2 sentences. You do not need an explanation for every feature, but for every group of features that are being transformed the same way. For example, \"I am doing transformation X to the following categorical features: `a`, `b`, `c` because of reason Y,\" etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"churn\"])\n",
    "X_test = test_df.drop(columns=[\"churn\"])\n",
    "\n",
    "y_train = train_df[\"churn\"]\n",
    "y_test = test_df[\"churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['account length', 'number vmail messages', 'total day minutes', 'total day calls', 'total eve minutes', \n",
    "                    'total eve calls', 'total night minutes', 'total night calls', 'total intl minutes', 'total intl calls', 'customer service calls']\n",
    "categorical_features = ['state', 'area code']\n",
    "binary_features = ['international plan', 'voice mail plan']\n",
    "drop_features = ['phone number', 'total day charge', 'total eve charge', 'total night charge', 'total intl charge']\n",
    "target = \"churn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lecture 6\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\", dtype=int, sparse=False), categorical_features),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse=False, dtype=int), binary_features),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need for imputers since there is no missing value.\n",
    "The numeric features above are scaled for logistic regression.\n",
    "\n",
    "The categorical features, `state` and `area code`, are one-hot encoded.\n",
    "\n",
    "The binary features, `international plan` and `voice mail plan`, are one-hot encoded with `drop='if_binary'` since there are only 2 distinct values for these features.\n",
    "\n",
    "Phone numbers are unique, non-numeric and non-ordinal, and doesn't carry any information. Total day/eve/night/intl charges linearly correlated to total day/eve/night/intl minutes, and therefore redundant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualizing the transformed data \n",
    "rubric={points:4}\n",
    "\n",
    "Fit and transform your `ColumnTransformer` on your training set. Print the first 5 rows of the transformed data as a dataframe (not numpy array). See lecture 10 for code that can get you the new column names after transforming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account length</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>...</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>area code_408</th>\n",
       "      <th>area code_415</th>\n",
       "      <th>area code_510</th>\n",
       "      <th>international plan_yes</th>\n",
       "      <th>voice mail plan_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>-0.767893</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>0.618769</td>\n",
       "      <td>-0.721211</td>\n",
       "      <td>0.069871</td>\n",
       "      <td>-1.156734</td>\n",
       "      <td>1.088667</td>\n",
       "      <td>0.052115</td>\n",
       "      <td>-1.645501</td>\n",
       "      <td>-0.200722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>-0.843585</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>-1.293778</td>\n",
       "      <td>1.655252</td>\n",
       "      <td>-1.167277</td>\n",
       "      <td>-1.207278</td>\n",
       "      <td>-2.162302</td>\n",
       "      <td>-0.720990</td>\n",
       "      <td>0.227019</td>\n",
       "      <td>0.198158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.544113</td>\n",
       "      <td>1.900976</td>\n",
       "      <td>-0.609809</td>\n",
       "      <td>0.169963</td>\n",
       "      <td>-2.210130</td>\n",
       "      <td>0.157417</td>\n",
       "      <td>0.369287</td>\n",
       "      <td>-0.463288</td>\n",
       "      <td>1.919489</td>\n",
       "      <td>-0.200722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>0.165650</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>0.998345</td>\n",
       "      <td>-0.473663</td>\n",
       "      <td>-0.754894</td>\n",
       "      <td>0.258506</td>\n",
       "      <td>1.597736</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>-0.097071</td>\n",
       "      <td>-0.599603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>0.115188</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>-0.994886</td>\n",
       "      <td>0.764078</td>\n",
       "      <td>1.195994</td>\n",
       "      <td>-0.246937</td>\n",
       "      <td>0.793839</td>\n",
       "      <td>0.206736</td>\n",
       "      <td>0.407069</td>\n",
       "      <td>1.793679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      account length  number vmail messages  total day minutes  \\\n",
       "1402       -0.767893              -0.587624           0.618769   \n",
       "1855       -0.843585              -0.587624          -1.293778   \n",
       "633         0.544113               1.900976          -0.609809   \n",
       "1483        0.165650              -0.587624           0.998345   \n",
       "2638        0.115188              -0.587624          -0.994886   \n",
       "\n",
       "      total day calls  total eve minutes  total eve calls  \\\n",
       "1402        -0.721211           0.069871        -1.156734   \n",
       "1855         1.655252          -1.167277        -1.207278   \n",
       "633          0.169963          -2.210130         0.157417   \n",
       "1483        -0.473663          -0.754894         0.258506   \n",
       "2638         0.764078           1.195994        -0.246937   \n",
       "\n",
       "      total night minutes  total night calls  total intl minutes  \\\n",
       "1402             1.088667           0.052115           -1.645501   \n",
       "1855            -2.162302          -0.720990            0.227019   \n",
       "633              0.369287          -0.463288            1.919489   \n",
       "1483             1.597736           0.000574           -0.097071   \n",
       "2638             0.793839           0.206736            0.407069   \n",
       "\n",
       "      total intl calls  ...  state_VT  state_WA  state_WI  state_WV  state_WY  \\\n",
       "1402         -0.200722  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1855          0.198158  ...       0.0       0.0       1.0       0.0       0.0   \n",
       "633          -0.200722  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1483         -0.599603  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "2638          1.793679  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      area code_408  area code_415  area code_510  international plan_yes  \\\n",
       "1402            0.0            1.0            0.0                     0.0   \n",
       "1855            0.0            0.0            1.0                     0.0   \n",
       "633             0.0            1.0            0.0                     0.0   \n",
       "1483            0.0            0.0            1.0                     1.0   \n",
       "2638            0.0            0.0            1.0                     0.0   \n",
       "\n",
       "      voice mail plan_yes  \n",
       "1402                  0.0  \n",
       "1855                  0.0  \n",
       "633                   1.0  \n",
       "1483                  0.0  \n",
       "2638                  0.0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed = preprocessor.fit_transform(X_train, y_train)\n",
    "preprocessor.named_transformers_.values()\n",
    "\n",
    "new_columns = []\n",
    "\n",
    "for tf in preprocessor.named_transformers_.values():\n",
    "    if tf != 'drop':\n",
    "        new_columns.extend(tf.get_feature_names_out())\n",
    "\n",
    "X_train_enc = pd.DataFrame(\n",
    "    preprocessor.transform(X_train), index=X_train.index, columns=new_columns\n",
    ")\n",
    "\n",
    "X_train_enc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['standardscaler__account length',\n",
       "       'standardscaler__number vmail messages',\n",
       "       'standardscaler__total day minutes',\n",
       "       'standardscaler__total day calls',\n",
       "       'standardscaler__total eve minutes',\n",
       "       'standardscaler__total eve calls',\n",
       "       'standardscaler__total night minutes',\n",
       "       'standardscaler__total night calls',\n",
       "       'standardscaler__total intl minutes',\n",
       "       'standardscaler__total intl calls',\n",
       "       'standardscaler__customer service calls',\n",
       "       'onehotencoder-1__state_AK', 'onehotencoder-1__state_AL',\n",
       "       'onehotencoder-1__state_AR', 'onehotencoder-1__state_AZ',\n",
       "       'onehotencoder-1__state_CA', 'onehotencoder-1__state_CO',\n",
       "       'onehotencoder-1__state_CT', 'onehotencoder-1__state_DC',\n",
       "       'onehotencoder-1__state_DE', 'onehotencoder-1__state_FL',\n",
       "       'onehotencoder-1__state_GA', 'onehotencoder-1__state_HI',\n",
       "       'onehotencoder-1__state_IA', 'onehotencoder-1__state_ID',\n",
       "       'onehotencoder-1__state_IL', 'onehotencoder-1__state_IN',\n",
       "       'onehotencoder-1__state_KS', 'onehotencoder-1__state_KY',\n",
       "       'onehotencoder-1__state_LA', 'onehotencoder-1__state_MA',\n",
       "       'onehotencoder-1__state_MD', 'onehotencoder-1__state_ME',\n",
       "       'onehotencoder-1__state_MI', 'onehotencoder-1__state_MN',\n",
       "       'onehotencoder-1__state_MO', 'onehotencoder-1__state_MS',\n",
       "       'onehotencoder-1__state_MT', 'onehotencoder-1__state_NC',\n",
       "       'onehotencoder-1__state_ND', 'onehotencoder-1__state_NE',\n",
       "       'onehotencoder-1__state_NH', 'onehotencoder-1__state_NJ',\n",
       "       'onehotencoder-1__state_NM', 'onehotencoder-1__state_NV',\n",
       "       'onehotencoder-1__state_NY', 'onehotencoder-1__state_OH',\n",
       "       'onehotencoder-1__state_OK', 'onehotencoder-1__state_OR',\n",
       "       'onehotencoder-1__state_PA', 'onehotencoder-1__state_RI',\n",
       "       'onehotencoder-1__state_SC', 'onehotencoder-1__state_SD',\n",
       "       'onehotencoder-1__state_TN', 'onehotencoder-1__state_TX',\n",
       "       'onehotencoder-1__state_UT', 'onehotencoder-1__state_VA',\n",
       "       'onehotencoder-1__state_VT', 'onehotencoder-1__state_WA',\n",
       "       'onehotencoder-1__state_WI', 'onehotencoder-1__state_WV',\n",
       "       'onehotencoder-1__state_WY', 'onehotencoder-1__area code_408',\n",
       "       'onehotencoder-1__area code_415', 'onehotencoder-1__area code_510',\n",
       "       'onehotencoder-2__international plan_yes',\n",
       "       'onehotencoder-2__voice mail plan_yes'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 area code feature\n",
    "rubric={points:4}\n",
    "\n",
    "The original dataset had a feature called `area code`. Let's assume we encoded this feature with one-hot encoding.\n",
    "\n",
    "1. The area codes were numbers to begin with. Why do we want to use one-hot encoding on this feature?\n",
    "2. What were the possible values of `area code`? \n",
    "3. What new feature(s) were created to replace `area code`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Although they are numbers, they are in fact identifiers consisting of digits. Area codes are non-ordinal.\n",
    "2. There are only 3 distinct values of `area code` in the dataset: [408, 415, 510].\n",
    "3. A new feature is created for each unique area code in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['state_AK', 'state_AL', 'state_AR', 'state_AZ', 'state_CA',\n",
       "       'state_CO', 'state_CT', 'state_DC', 'state_DE', 'state_FL',\n",
       "       'state_GA', 'state_HI', 'state_IA', 'state_ID', 'state_IL',\n",
       "       'state_IN', 'state_KS', 'state_KY', 'state_LA', 'state_MA',\n",
       "       'state_MD', 'state_ME', 'state_MI', 'state_MN', 'state_MO',\n",
       "       'state_MS', 'state_MT', 'state_NC', 'state_ND', 'state_NE',\n",
       "       'state_NH', 'state_NJ', 'state_NM', 'state_NV', 'state_NY',\n",
       "       'state_OH', 'state_OK', 'state_OR', 'state_PA', 'state_RI',\n",
       "       'state_SC', 'state_SD', 'state_TN', 'state_TX', 'state_UT',\n",
       "       'state_VA', 'state_VT', 'state_WA', 'state_WI', 'state_WV',\n",
       "       'state_WY', 'area code_408', 'area code_415', 'area code_510'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.named_transformers_['onehotencoder-1'].get_feature_names_out(categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New features created for each unique area code in the training data: `area code_408`, `area code_415`, `area code_510`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Dummy classifier\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Create a `DummyClassifier`. Report the following scoring metrics via cross-validation: accuracy, precision, recall, f1-score. Briefly comment on your results, including any *warnings* the code produces (2 sentences max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenny\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kenny\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kenny\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kenny\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kenny\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kenny\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kenny\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kenny\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kenny\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Kenny\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014960</td>\n",
       "      <td>0.011489</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.850482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.850482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.850482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>0.851931</td>\n",
       "      <td>0.850027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011969</td>\n",
       "      <td>0.008948</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.850562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy  test_f1  train_f1  \\\n",
       "0  0.014960    0.011489       0.850107        0.850482      0.0       0.0   \n",
       "1  0.009973    0.005984       0.850107        0.850482      0.0       0.0   \n",
       "2  0.007979    0.006642       0.850107        0.850482      0.0       0.0   \n",
       "3  0.012940    0.008976       0.851931        0.850027      0.0       0.0   \n",
       "4  0.011969    0.008948       0.849785        0.850562      0.0       0.0   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0          0.0           0.0             0.0              0.0  \n",
       "1          0.0           0.0             0.0              0.0  \n",
       "2          0.0           0.0             0.0              0.0  \n",
       "3          0.0           0.0             0.0              0.0  \n",
       "4          0.0           0.0             0.0              0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyClassifier()\n",
    "\n",
    "# from Lecture 9\n",
    "scoring = [\n",
    "    \"accuracy\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "]  # scoring can be a string, a list, or a dictionary\n",
    "\n",
    "pipeline = make_pipeline(preprocessor, dummy)\n",
    "\n",
    "cv = pd.DataFrame(cross_validate(pipeline, X_train, y_train, cv=5, return_train_score=True, scoring=scoring))\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1984\n",
       "True      349\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the dummy classifier only predicts the most common target value, which is the negative class for these training folds, it never predicts any example as a positive, and thus the recall is zero, and hence the f1 is also zero for all.\n",
    "Furthermore, the denominator of the precision (FP + TP) is also always zero, and causes a warning about 'division by zero'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Logistic regression\n",
    "rubric={points:8} \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Train and score a logistic regression classifier on the dataset. \n",
    "2. Report the same metrics as in the previous part.\n",
    "3. Are you satisfied with the results? Use your `DummyClassifier` results as a reference point. Discuss in a few sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_enc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037897</td>\n",
       "      <td>0.011968</td>\n",
       "      <td>0.869379</td>\n",
       "      <td>0.864416</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.332454</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040892</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.852248</td>\n",
       "      <td>0.868167</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.362694</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.250896</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.654206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.045878</td>\n",
       "      <td>0.012966</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.867095</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.364103</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.254480</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.639640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.041890</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>0.869099</td>\n",
       "      <td>0.863953</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.345361</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.239286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056894</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.839056</td>\n",
       "      <td>0.868773</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.373402</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.261649</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  0.037897    0.011968       0.869379        0.864416  0.371134  0.332454   \n",
       "1  0.040892    0.010970       0.852248        0.868167  0.273684  0.362694   \n",
       "2  0.045878    0.012966       0.850107        0.867095  0.255319  0.364103   \n",
       "3  0.041890    0.012963       0.869099        0.863953  0.371134  0.345361   \n",
       "4  0.056894    0.013963       0.839056        0.868773  0.242424  0.373402   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0     0.257143      0.225806        0.666667         0.630000  \n",
       "1     0.185714      0.250896        0.520000         0.654206  \n",
       "2     0.171429      0.254480        0.500000         0.639640  \n",
       "3     0.260870      0.239286        0.642857         0.620370  \n",
       "4     0.171429      0.261649        0.413793         0.651786  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring = [\n",
    "    \"accuracy\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "]  # scoring can be a string, a list, or a dictionary\n",
    "\n",
    "pipeline_lr = make_pipeline(preprocessor, lr)\n",
    "\n",
    "cv = pd.DataFrame(cross_validate(pipeline_lr, X_train, y_train, cv=5, return_train_score=True, scoring=scoring))\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall is very low; there are a lot of false negatives. This is still much better than the dummy model in terms of recall, f1, and precision. The accuracy is still similar to that of the dummy model due to class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Logistic regression with `class_weight`\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Set the `class_weight` parameter of your logistic regression model to `'balanced'` and report the same metrics as in the previous part. \n",
    "2. Do you prefer this model to the one in the previous part? Discuss your results in a few sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040893</td>\n",
       "      <td>0.014471</td>\n",
       "      <td>0.785867</td>\n",
       "      <td>0.770096</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.498246</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.369792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034906</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.768737</td>\n",
       "      <td>0.771168</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.504065</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.366197</td>\n",
       "      <td>0.372852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038896</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.764454</td>\n",
       "      <td>0.774384</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>0.511034</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.788530</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.378007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035004</td>\n",
       "      <td>0.011870</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.778790</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.516959</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.789286</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.384348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033937</td>\n",
       "      <td>0.011346</td>\n",
       "      <td>0.733906</td>\n",
       "      <td>0.786824</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.531765</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.810036</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.395797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  0.040893    0.014471       0.785867        0.770096  0.489796  0.498246   \n",
       "1  0.034906    0.009973       0.768737        0.771168  0.490566  0.504065   \n",
       "2  0.038896    0.010970       0.764454        0.774384  0.455446  0.511034   \n",
       "3  0.035004    0.011870       0.751073        0.778790  0.462963  0.516959   \n",
       "4  0.033937    0.011346       0.733906        0.786824  0.436364  0.531765   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0     0.685714      0.763441        0.380952         0.369792  \n",
       "1     0.742857      0.777778        0.366197         0.372852  \n",
       "2     0.657143      0.788530        0.348485         0.378007  \n",
       "3     0.724638      0.789286        0.340136         0.384348  \n",
       "4     0.685714      0.810036        0.320000         0.395797  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_bal = LogisticRegression(class_weight='balanced')\n",
    "pipeline_lr_bal = make_pipeline(preprocessor, lr_bal)\n",
    "cv = pd.DataFrame(cross_validate(pipeline_lr_bal, X_train, y_train, cv=5, return_train_score=True, scoring=scoring))\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy got lower than the baseline dummy model, and the precision is also lower than the model from the previous. However, the (validation) recall and f1 improved with balanced class weight, but I still do not prefer this model to the one in the previous part because it produces too many false positives (low precision)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Hyperparameter optimization\n",
    "rubric={points:10}\n",
    "\n",
    "Now let's tune the hyperparameters of our `LogisticRegression` using `GridSearchCV` to maximize cross-validation f1 score. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Jointly optimize `C` (choose some reasonable values) and `class_weight` (`None` vs. `'balanced'`) with `GridSearchCV` and `scoring=\"f1\"`. \n",
    "2. What values of `C` and `class_weight` are chosen and what is the best cross-validation f1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['account '\n",
       "                                                                          'length',\n",
       "                                                                          'number '\n",
       "                                                                          'vmail '\n",
       "                                                                          'messages',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'minutes',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'calls',\n",
       "                                                                          'total '\n",
       "                                                                          'eve '\n",
       "                                                                          'minutes',\n",
       "                                                                          'total '\n",
       "                                                                          'eve '\n",
       "                                                                          'calls',\n",
       "                                                                          'total '\n",
       "                                                                          'night '\n",
       "                                                                          'minutes',\n",
       "                                                                          'total '\n",
       "                                                                          'night '\n",
       "                                                                          'calls',\n",
       "                                                                          'total '\n",
       "                                                                          'intl '\n",
       "                                                                          'minutes',\n",
       "                                                                          'total '\n",
       "                                                                          'intl '\n",
       "                                                                          'calls'...\n",
       "                                                                          'mail '\n",
       "                                                                          'plan']),\n",
       "                                                                        ('drop',\n",
       "                                                                         'drop',\n",
       "                                                                         ['phone '\n",
       "                                                                          'number',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'charge',\n",
       "                                                                          'total '\n",
       "                                                                          'eve '\n",
       "                                                                          'charge',\n",
       "                                                                          'total '\n",
       "                                                                          'night '\n",
       "                                                                          'charge',\n",
       "                                                                          'total '\n",
       "                                                                          'intl '\n",
       "                                                                          'charge'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logisticregression__C': [0.001, 0.01, 0.1, 1.0, 10,\n",
       "                                                   100],\n",
       "                         'logisticregression__class_weight': [None,\n",
       "                                                              'balanced']},\n",
       "             return_train_score=True, scoring='f1')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"logisticregression__class_weight\": [None, 'balanced'],\n",
    "    \"logisticregression__C\": [0.001, 0.01, 0.1, 1.0, 10, 100],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_lr, param_grid, cv=5, n_jobs=-1, return_train_score=True, scoring=\"f1\"\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1: 0.47787\n"
     ]
    }
   ],
   "source": [
    "print(f'Best f1: {grid_search.best_score_:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 0.1\n",
      "Best class_weight: \"balanced\"\n"
     ]
    }
   ],
   "source": [
    "print(f'Best C: {grid_search.best_params_[\"logisticregression__C\"]}')\n",
    "print(f'Best class_weight: \"{grid_search.best_params_[\"logisticregression__class_weight\"]}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Test results\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks**\n",
    "1. Evaluate the best model on the test set. In particular show each of the following on the test set:  \n",
    "    - Confusion matrix. \n",
    "    - Classification report. \n",
    "    - Precision-recall curve with average precision score.     \n",
    "    - ROC curve with AUC. \n",
    "3. Comment on the results.    \n",
    "\n",
    "> Note that we are not doing it here but in real life, you would also plot confusion matrix, precision-recall curve, and ROC curve on validation data to examine errors and to choose a threshold which works for your operating point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['account length',\n",
       "                                                   'number vmail messages',\n",
       "                                                   'total day minutes',\n",
       "                                                   'total day calls',\n",
       "                                                   'total eve minutes',\n",
       "                                                   'total eve calls',\n",
       "                                                   'total night minutes',\n",
       "                                                   'total night calls',\n",
       "                                                   'total intl minutes',\n",
       "                                                   'total intl calls',\n",
       "                                                   'customer service calls']),\n",
       "                                                 ('onehotencoder-1',\n",
       "                                                  OneHotEncoder(dtype=<...\n",
       "                                                                sparse=False),\n",
       "                                                  ['state', 'area code']),\n",
       "                                                 ('onehotencoder-2',\n",
       "                                                  OneHotEncoder(drop='if_binary',\n",
       "                                                                dtype=<class 'int'>,\n",
       "                                                                handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  ['international plan',\n",
       "                                                   'voice mail plan']),\n",
       "                                                 ('drop', 'drop',\n",
       "                                                  ['phone number',\n",
       "                                                   'total day charge',\n",
       "                                                   'total eve charge',\n",
       "                                                   'total night charge',\n",
       "                                                   'total intl charge'])])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.1, class_weight='balanced'))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = grid_search.best_estimator_\n",
    "best_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[670, 196],\n",
       "       [ 31, 103]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, best_lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.77      0.86       866\n",
      "        True       0.34      0.77      0.48       134\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.65      0.77      0.67      1000\n",
      "weighted avg       0.87      0.77      0.80      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    y_test, best_lr.predict(X_test), target_names=[\"False\", \"True\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision of logistic regression: 0.457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22a0aeef190>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# From Lecture 9\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_test, best_lr.predict_proba(X_test)[:, 1]\n",
    ")\n",
    "\n",
    "ap_lr = average_precision_score(y_test, best_lr.predict_proba(X_test)[:, 1])\n",
    "print(\"Average precision of logistic regression: {:.3f}\".format(ap_lr))\n",
    "\n",
    "plt.plot(precision, recall, label=\"logistic regression: PR curve\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.plot(\n",
    "    precision_score(y_test, best_lr.predict(X_test)),\n",
    "    recall_score(y_test, best_lr.predict(X_test)),\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for SVC: 0.823\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adapted from Lecture 9\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "preds = best_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_lr = roc_auc_score(y_test, preds)\n",
    "print(\"AUC for SVC: {:.3f}\".format(roc_lr))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, preds)\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "\n",
    "default_threshold = np.argmin(np.abs(thresholds - 0.5))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[default_threshold],\n",
    "    tpr[default_threshold],\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks as though we can't achieve both high recall and precision by moving the threshold. And high TPR can't be achieved without also increasing the FPR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Regression metrics <a name=\"3\"></a>\n",
    "<hr> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) from `sklearn datasets`. The code below loads the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing_df = fetch_california_housing(as_frame=True).frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fetch_california_housing(as_frame=True)### 3.1: Data spitting and exploration \n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train (80%) and test (20%) splits. \n",
    "2. Explore the train split. Do you need to apply any transformations on the data? If yes, create a preprocessor with the appropriate transformations. \n",
    "3. Separate `X` and `y` in train and test splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "An household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surpinsingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fetch_california_housing(as_frame=True).DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(housing_df, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.870716</td>\n",
       "      <td>28.570918</td>\n",
       "      <td>5.422508</td>\n",
       "      <td>1.096515</td>\n",
       "      <td>1434.115734</td>\n",
       "      <td>3.064722</td>\n",
       "      <td>35.627757</td>\n",
       "      <td>-119.566976</td>\n",
       "      <td>2.069687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.900132</td>\n",
       "      <td>12.582281</td>\n",
       "      <td>2.520931</td>\n",
       "      <td>0.491311</td>\n",
       "      <td>1130.309986</td>\n",
       "      <td>10.624706</td>\n",
       "      <td>2.134543</td>\n",
       "      <td>2.000519</td>\n",
       "      <td>1.154148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "      <td>0.149990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.562500</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.430476</td>\n",
       "      <td>1.005825</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>2.429013</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.800000</td>\n",
       "      <td>1.194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.529400</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.227170</td>\n",
       "      <td>1.048765</td>\n",
       "      <td>1170.000000</td>\n",
       "      <td>2.816122</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>-118.490000</td>\n",
       "      <td>1.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.750375</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.051005</td>\n",
       "      <td>1.099493</td>\n",
       "      <td>1735.000000</td>\n",
       "      <td>3.278954</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>-118.010000</td>\n",
       "      <td>2.647250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>28566.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "      <td>5.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  16512.000000  16512.000000  16512.000000  16512.000000  16512.000000   \n",
       "mean       3.870716     28.570918      5.422508      1.096515   1434.115734   \n",
       "std        1.900132     12.582281      2.520931      0.491311   1130.309986   \n",
       "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
       "25%        2.562500     18.000000      4.430476      1.005825    789.000000   \n",
       "50%        3.529400     29.000000      5.227170      1.048765   1170.000000   \n",
       "75%        4.750375     37.000000      6.051005      1.099493   1735.000000   \n",
       "max       15.000100     52.000000    141.909091     34.066667  28566.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude   MedHouseVal  \n",
       "count  16512.000000  16512.000000  16512.000000  16512.000000  \n",
       "mean       3.064722     35.627757   -119.566976      2.069687  \n",
       "std       10.624706      2.134543      2.000519      1.154148  \n",
       "min        0.750000     32.540000   -124.350000      0.149990  \n",
       "25%        2.429013     33.930000   -121.800000      1.194000  \n",
       "50%        2.816122     34.250000   -118.490000      1.804000  \n",
       "75%        3.278954     37.710000   -118.010000      2.647250  \n",
       "max     1243.333333     41.950000   -114.310000      5.000010  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16512 entries, 9950 to 19966\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MedInc       16512 non-null  float64\n",
      " 1   HouseAge     16512 non-null  float64\n",
      " 2   AveRooms     16512 non-null  float64\n",
      " 3   AveBedrms    16512 non-null  float64\n",
      " 4   Population   16512 non-null  float64\n",
      " 5   AveOccup     16512 non-null  float64\n",
      " 6   Latitude     16512 non-null  float64\n",
      " 7   Longitude    16512 non-null  float64\n",
      " 8   MedHouseVal  16512 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scl = StandardScaler() # All features appear to be numeric, and require scaling for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['MedHouseVal'])\n",
    "y_train = train_df['MedHouseVal']\n",
    "X_test = test_df.drop(columns=['MedHouseVal'])\n",
    "y_test = test_df['MedHouseVal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Baseline: DummyRegressor \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out cross-validation using `DummyRegressor` with default scoring. \n",
    "2. What metric is used for scoring by default? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005016</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004008</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005959</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.005016    0.001996   -0.000023          0.0\n",
       "1  0.002992    0.001966   -0.000576          0.0\n",
       "2  0.004008    0.000968   -0.000061          0.0\n",
       "3  0.005959    0.002990   -0.000015          0.0\n",
       "4  0.003020    0.000969   -0.000058          0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyRegressor()\n",
    "cv = pd.DataFrame(cross_validate(make_pipeline(std_scl, dummy), X_train, y_train, return_train_score=True))\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is used by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Different regressors\n",
    "rubric={points:8}\n",
    "\n",
    "In this exercise, we are going to use [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) model which we haven't looked into yet. At this point you should feel comfortable using models with our usual ML workflow even if you don't know the details. We'll talk about `RandomForestRegressor` later in the course.  \n",
    "\n",
    "The code below defines a custom scorer called `mape_scorer` and creates dictionaries for different regressors (`models`) and different scoring metrics (`score_types_reg`). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Using the `models` and the evaluation metrics `score_types_reg` in the code below, carry out cross-validation with each model, by passing the evaluation metrics to `scoring` argument of `cross_validate`. Use a pipeline with the model as an estimator if you are applying any transformations. \n",
    "2. Show results as a dataframe. \n",
    "3. Interpret the results. How do the models compare to the baseline? Which model seems to be performing well with different metrics? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(true, pred):\n",
    "    return 100.0 * np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "# make a scorer function that we can pass into cross-validation\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "models = {\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "score_types_reg = {\n",
    "    \"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
    "    \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"mape_scorer\": mape_scorer,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Lecture 10\n",
    "evaluation_metrics = {}\n",
    "pipelines = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipelines[name] = make_pipeline(std_scl, model)\n",
    "    evaluation_metrics[name] = pd.DataFrame(\n",
    "        cross_validate(\n",
    "            pipelines[name], X_train, y_train, return_train_score=True, scoring=score_types_reg\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>train_neg_mean_squared_error</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_mape_scorer</th>\n",
       "      <th>train_mape_scorer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037897</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>-0.543796</td>\n",
       "      <td>-0.523434</td>\n",
       "      <td>-0.737425</td>\n",
       "      <td>-0.723487</td>\n",
       "      <td>-0.537722</td>\n",
       "      <td>-0.530319</td>\n",
       "      <td>0.600728</td>\n",
       "      <td>0.604798</td>\n",
       "      <td>-32.879669</td>\n",
       "      <td>-31.565152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>-0.523154</td>\n",
       "      <td>-0.526913</td>\n",
       "      <td>-0.723294</td>\n",
       "      <td>-0.725888</td>\n",
       "      <td>-0.538830</td>\n",
       "      <td>-0.531133</td>\n",
       "      <td>0.609386</td>\n",
       "      <td>0.603822</td>\n",
       "      <td>-31.382857</td>\n",
       "      <td>-31.924930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>-0.530828</td>\n",
       "      <td>-0.524935</td>\n",
       "      <td>-0.728579</td>\n",
       "      <td>-0.724524</td>\n",
       "      <td>-0.529630</td>\n",
       "      <td>-0.533808</td>\n",
       "      <td>0.611168</td>\n",
       "      <td>0.603422</td>\n",
       "      <td>-31.636865</td>\n",
       "      <td>-31.937245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008978</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>-0.526309</td>\n",
       "      <td>-0.526141</td>\n",
       "      <td>-0.725472</td>\n",
       "      <td>-0.725356</td>\n",
       "      <td>-0.534463</td>\n",
       "      <td>-0.532982</td>\n",
       "      <td>0.599991</td>\n",
       "      <td>0.606191</td>\n",
       "      <td>-31.977278</td>\n",
       "      <td>-31.841225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>-1.293077</td>\n",
       "      <td>-0.520423</td>\n",
       "      <td>-1.137135</td>\n",
       "      <td>-0.721403</td>\n",
       "      <td>-0.536574</td>\n",
       "      <td>-0.528700</td>\n",
       "      <td>-0.012554</td>\n",
       "      <td>0.613268</td>\n",
       "      <td>-32.021087</td>\n",
       "      <td>-31.546342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_squared_error  \\\n",
       "0  0.037897    0.002991                    -0.543796   \n",
       "1  0.003990    0.003989                    -0.523154   \n",
       "2  0.004987    0.003988                    -0.530828   \n",
       "3  0.008978    0.003988                    -0.526309   \n",
       "4  0.003989    0.003988                    -1.293077   \n",
       "\n",
       "   train_neg_mean_squared_error  test_neg_root_mean_squared_error  \\\n",
       "0                     -0.523434                         -0.737425   \n",
       "1                     -0.526913                         -0.723294   \n",
       "2                     -0.524935                         -0.728579   \n",
       "3                     -0.526141                         -0.725472   \n",
       "4                     -0.520423                         -1.137135   \n",
       "\n",
       "   train_neg_root_mean_squared_error  test_neg_mean_absolute_error  \\\n",
       "0                          -0.723487                     -0.537722   \n",
       "1                          -0.725888                     -0.538830   \n",
       "2                          -0.724524                     -0.529630   \n",
       "3                          -0.725356                     -0.534463   \n",
       "4                          -0.721403                     -0.536574   \n",
       "\n",
       "   train_neg_mean_absolute_error   test_r2  train_r2  test_mape_scorer  \\\n",
       "0                      -0.530319  0.600728  0.604798        -32.879669   \n",
       "1                      -0.531133  0.609386  0.603822        -31.382857   \n",
       "2                      -0.533808  0.611168  0.603422        -31.636865   \n",
       "3                      -0.532982  0.599991  0.606191        -31.977278   \n",
       "4                      -0.528700 -0.012554  0.613268        -32.021087   \n",
       "\n",
       "   train_mape_scorer  \n",
       "0         -31.565152  \n",
       "1         -31.924930  \n",
       "2         -31.937245  \n",
       "3         -31.841225  \n",
       "4         -31.546342  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics[\"Ridge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>train_neg_mean_squared_error</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_mape_scorer</th>\n",
       "      <th>train_mape_scorer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.359130</td>\n",
       "      <td>0.079935</td>\n",
       "      <td>-0.254950</td>\n",
       "      <td>-0.038349</td>\n",
       "      <td>-0.504926</td>\n",
       "      <td>-0.195829</td>\n",
       "      <td>-0.335222</td>\n",
       "      <td>-0.127173</td>\n",
       "      <td>0.812807</td>\n",
       "      <td>0.971046</td>\n",
       "      <td>-19.742811</td>\n",
       "      <td>-7.205316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.464156</td>\n",
       "      <td>0.081782</td>\n",
       "      <td>-0.259065</td>\n",
       "      <td>-0.036013</td>\n",
       "      <td>-0.508984</td>\n",
       "      <td>-0.189770</td>\n",
       "      <td>-0.330376</td>\n",
       "      <td>-0.123167</td>\n",
       "      <td>0.806568</td>\n",
       "      <td>0.972923</td>\n",
       "      <td>-17.908265</td>\n",
       "      <td>-6.972989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.328905</td>\n",
       "      <td>0.080784</td>\n",
       "      <td>-0.258229</td>\n",
       "      <td>-0.036909</td>\n",
       "      <td>-0.508163</td>\n",
       "      <td>-0.192117</td>\n",
       "      <td>-0.330705</td>\n",
       "      <td>-0.125547</td>\n",
       "      <td>0.810847</td>\n",
       "      <td>0.972116</td>\n",
       "      <td>-18.455055</td>\n",
       "      <td>-7.072868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.240307</td>\n",
       "      <td>0.077792</td>\n",
       "      <td>-0.281374</td>\n",
       "      <td>-0.036363</td>\n",
       "      <td>-0.530447</td>\n",
       "      <td>-0.190690</td>\n",
       "      <td>-0.344333</td>\n",
       "      <td>-0.124293</td>\n",
       "      <td>0.786148</td>\n",
       "      <td>0.972783</td>\n",
       "      <td>-19.323079</td>\n",
       "      <td>-6.980604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.454402</td>\n",
       "      <td>0.095770</td>\n",
       "      <td>-0.262110</td>\n",
       "      <td>-0.036436</td>\n",
       "      <td>-0.511966</td>\n",
       "      <td>-0.190882</td>\n",
       "      <td>-0.331406</td>\n",
       "      <td>-0.124322</td>\n",
       "      <td>0.794753</td>\n",
       "      <td>0.972924</td>\n",
       "      <td>-18.867800</td>\n",
       "      <td>-7.004195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_squared_error  \\\n",
       "0  6.359130    0.079935                    -0.254950   \n",
       "1  6.464156    0.081782                    -0.259065   \n",
       "2  6.328905    0.080784                    -0.258229   \n",
       "3  6.240307    0.077792                    -0.281374   \n",
       "4  6.454402    0.095770                    -0.262110   \n",
       "\n",
       "   train_neg_mean_squared_error  test_neg_root_mean_squared_error  \\\n",
       "0                     -0.038349                         -0.504926   \n",
       "1                     -0.036013                         -0.508984   \n",
       "2                     -0.036909                         -0.508163   \n",
       "3                     -0.036363                         -0.530447   \n",
       "4                     -0.036436                         -0.511966   \n",
       "\n",
       "   train_neg_root_mean_squared_error  test_neg_mean_absolute_error  \\\n",
       "0                          -0.195829                     -0.335222   \n",
       "1                          -0.189770                     -0.330376   \n",
       "2                          -0.192117                     -0.330705   \n",
       "3                          -0.190690                     -0.344333   \n",
       "4                          -0.190882                     -0.331406   \n",
       "\n",
       "   train_neg_mean_absolute_error   test_r2  train_r2  test_mape_scorer  \\\n",
       "0                      -0.127173  0.812807  0.971046        -19.742811   \n",
       "1                      -0.123167  0.806568  0.972923        -17.908265   \n",
       "2                      -0.125547  0.810847  0.972116        -18.455055   \n",
       "3                      -0.124293  0.786148  0.972783        -19.323079   \n",
       "4                      -0.124322  0.794753  0.972924        -18.867800   \n",
       "\n",
       "   train_mape_scorer  \n",
       "0          -7.205316  \n",
       "1          -6.972989  \n",
       "2          -7.072868  \n",
       "3          -6.980604  \n",
       "4          -7.004195  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics[\"Random Forest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>train_neg_mean_squared_error</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_mape_scorer</th>\n",
       "      <th>train_mape_scorer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>-1.361999</td>\n",
       "      <td>-1.324473</td>\n",
       "      <td>-1.167047</td>\n",
       "      <td>-1.150857</td>\n",
       "      <td>-0.925567</td>\n",
       "      <td>-0.908210</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-64.806089</td>\n",
       "      <td>-61.662963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>-1.340083</td>\n",
       "      <td>-1.329990</td>\n",
       "      <td>-1.157619</td>\n",
       "      <td>-1.153252</td>\n",
       "      <td>-0.913790</td>\n",
       "      <td>-0.909615</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-60.240623</td>\n",
       "      <td>-62.478846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>-1.365269</td>\n",
       "      <td>-1.323661</td>\n",
       "      <td>-1.168447</td>\n",
       "      <td>-1.150505</td>\n",
       "      <td>-0.923830</td>\n",
       "      <td>-0.908809</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-63.192410</td>\n",
       "      <td>-62.100927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>-1.315762</td>\n",
       "      <td>-1.336032</td>\n",
       "      <td>-1.147067</td>\n",
       "      <td>-1.155869</td>\n",
       "      <td>-0.904008</td>\n",
       "      <td>-0.913543</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-62.183779</td>\n",
       "      <td>-62.306641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>-1.277119</td>\n",
       "      <td>-1.345694</td>\n",
       "      <td>-1.130097</td>\n",
       "      <td>-1.160041</td>\n",
       "      <td>-0.890301</td>\n",
       "      <td>-0.917164</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-60.827703</td>\n",
       "      <td>-62.686551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_squared_error  \\\n",
       "0  0.006982    0.004987                    -1.361999   \n",
       "1  0.003989    0.001995                    -1.340083   \n",
       "2  0.004986    0.001996                    -1.365269   \n",
       "3  0.006984    0.004984                    -1.315762   \n",
       "4  0.010970    0.003989                    -1.277119   \n",
       "\n",
       "   train_neg_mean_squared_error  test_neg_root_mean_squared_error  \\\n",
       "0                     -1.324473                         -1.167047   \n",
       "1                     -1.329990                         -1.157619   \n",
       "2                     -1.323661                         -1.168447   \n",
       "3                     -1.336032                         -1.147067   \n",
       "4                     -1.345694                         -1.130097   \n",
       "\n",
       "   train_neg_root_mean_squared_error  test_neg_mean_absolute_error  \\\n",
       "0                          -1.150857                     -0.925567   \n",
       "1                          -1.153252                     -0.913790   \n",
       "2                          -1.150505                     -0.923830   \n",
       "3                          -1.155869                     -0.904008   \n",
       "4                          -1.160041                     -0.890301   \n",
       "\n",
       "   train_neg_mean_absolute_error   test_r2  train_r2  test_mape_scorer  \\\n",
       "0                      -0.908210 -0.000023       0.0        -64.806089   \n",
       "1                      -0.909615 -0.000576       0.0        -60.240623   \n",
       "2                      -0.908809 -0.000061       0.0        -63.192410   \n",
       "3                      -0.913543 -0.000015       0.0        -62.183779   \n",
       "4                      -0.917164 -0.000058       0.0        -60.827703   \n",
       "\n",
       "   train_mape_scorer  \n",
       "0         -61.662963  \n",
       "1         -62.478846  \n",
       "2         -62.100927  \n",
       "3         -62.306641  \n",
       "4         -62.686551  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cross_validate(make_pipeline(std_scl, dummy), X_train, y_train, return_train_score=True, scoring=score_types_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time                              6.357412\n",
       "score_time                            0.079424\n",
       "test_neg_mean_squared_error           0.420287\n",
       "train_neg_mean_squared_error          0.487555\n",
       "test_neg_root_mean_squared_error      0.297484\n",
       "train_neg_root_mean_squared_error     0.532274\n",
       "test_neg_mean_absolute_error          0.201035\n",
       "train_neg_mean_absolute_error         0.406488\n",
       "test_r2                               0.320481\n",
       "train_r2                              0.366058\n",
       "test_mape_scorer                     13.120149\n",
       "train_mape_scorer                    24.715784\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics[\"Random Forest\"].mean() - evaluation_metrics[\"Ridge\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models are significantly better than the baseline in terms of all of the evaluation metrics. The \"Random Forest\" model is better than the \"Ridge\" model in every metric listed here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 3.4 Hyperparameter optimization \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out hyperparameter optimization using `RandomizedSearchCV` and `Ridge` with the following `param_dist`. The `alpha` hyperparameter of `Ridge` controls the fundamental tradeoff. Choose the metric of your choice for hyperparameter optimization. \n",
    "2. Are you getting better scores compared to the default values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "param_dist = {\"ridge__alpha\": loguniform(1e-3, 1e3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ridge__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025133</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>15.094374</td>\n",
       "      <td>{'ridge__alpha': 15.094374246471327}</td>\n",
       "      <td>0.601302</td>\n",
       "      <td>0.609083</td>\n",
       "      <td>0.611143</td>\n",
       "      <td>0.599832</td>\n",
       "      <td>-0.014181</td>\n",
       "      <td>0.481436</td>\n",
       "      <td>0.247846</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016754</td>\n",
       "      <td>0.004058</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>{'ridge__alpha': 0.05209979442925436}</td>\n",
       "      <td>0.600687</td>\n",
       "      <td>0.609405</td>\n",
       "      <td>0.611168</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.012443</td>\n",
       "      <td>0.481763</td>\n",
       "      <td>0.247144</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011170</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.022967</td>\n",
       "      <td>{'ridge__alpha': 0.022967235384741526}</td>\n",
       "      <td>0.600686</td>\n",
       "      <td>0.609406</td>\n",
       "      <td>0.611168</td>\n",
       "      <td>0.600001</td>\n",
       "      <td>-0.012440</td>\n",
       "      <td>0.481764</td>\n",
       "      <td>0.247143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012766</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>2.031836</td>\n",
       "      <td>{'ridge__alpha': 2.0318358298265977}</td>\n",
       "      <td>0.600772</td>\n",
       "      <td>0.609365</td>\n",
       "      <td>0.611167</td>\n",
       "      <td>0.599981</td>\n",
       "      <td>-0.012674</td>\n",
       "      <td>0.481722</td>\n",
       "      <td>0.247239</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019252</td>\n",
       "      <td>0.009755</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>20.740242</td>\n",
       "      <td>{'ridge__alpha': 20.740241962891858}</td>\n",
       "      <td>0.601515</td>\n",
       "      <td>0.608953</td>\n",
       "      <td>0.611123</td>\n",
       "      <td>0.599758</td>\n",
       "      <td>-0.014821</td>\n",
       "      <td>0.481306</td>\n",
       "      <td>0.248101</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.025435</td>\n",
       "      <td>0.017880</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.345652</td>\n",
       "      <td>{'ridge__alpha': 0.34565175058380543}</td>\n",
       "      <td>0.600699</td>\n",
       "      <td>0.609399</td>\n",
       "      <td>0.611168</td>\n",
       "      <td>0.599997</td>\n",
       "      <td>-0.012477</td>\n",
       "      <td>0.481757</td>\n",
       "      <td>0.247158</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.017656</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>766.628906</td>\n",
       "      <td>{'ridge__alpha': 766.6289057556017}</td>\n",
       "      <td>0.595454</td>\n",
       "      <td>0.581754</td>\n",
       "      <td>0.592100</td>\n",
       "      <td>0.575095</td>\n",
       "      <td>-0.052151</td>\n",
       "      <td>0.458450</td>\n",
       "      <td>0.255404</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.014270</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>12.852228</td>\n",
       "      <td>{'ridge__alpha': 12.852228299703652}</td>\n",
       "      <td>0.601215</td>\n",
       "      <td>0.609133</td>\n",
       "      <td>0.611150</td>\n",
       "      <td>0.599860</td>\n",
       "      <td>-0.013925</td>\n",
       "      <td>0.481486</td>\n",
       "      <td>0.247744</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.016157</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.768407</td>\n",
       "      <td>{'ridge__alpha': 0.7684071705306554}</td>\n",
       "      <td>0.600718</td>\n",
       "      <td>0.609391</td>\n",
       "      <td>0.611168</td>\n",
       "      <td>0.599993</td>\n",
       "      <td>-0.012527</td>\n",
       "      <td>0.481749</td>\n",
       "      <td>0.247178</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.225271</td>\n",
       "      <td>{'ridge__alpha': 0.22527090779355338}</td>\n",
       "      <td>0.600694</td>\n",
       "      <td>0.609402</td>\n",
       "      <td>0.611168</td>\n",
       "      <td>0.599999</td>\n",
       "      <td>-0.012463</td>\n",
       "      <td>0.481760</td>\n",
       "      <td>0.247152</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.025133      0.008306         0.002793        0.000747   \n",
       "1       0.016754      0.004058         0.002794        0.000400   \n",
       "2       0.011170      0.000746         0.003989        0.001546   \n",
       "3       0.012766      0.001465         0.002992        0.001091   \n",
       "4       0.019252      0.009755         0.003988        0.001261   \n",
       "5       0.025435      0.017880         0.004889        0.001109   \n",
       "6       0.017656      0.009906         0.003493        0.000894   \n",
       "7       0.014270      0.001026         0.002594        0.000489   \n",
       "8       0.016157      0.003302         0.003191        0.000746   \n",
       "9       0.013963      0.002185         0.003989        0.001260   \n",
       "\n",
       "  param_ridge__alpha                                  params  \\\n",
       "0          15.094374    {'ridge__alpha': 15.094374246471327}   \n",
       "1             0.0521   {'ridge__alpha': 0.05209979442925436}   \n",
       "2           0.022967  {'ridge__alpha': 0.022967235384741526}   \n",
       "3           2.031836    {'ridge__alpha': 2.0318358298265977}   \n",
       "4          20.740242    {'ridge__alpha': 20.740241962891858}   \n",
       "5           0.345652   {'ridge__alpha': 0.34565175058380543}   \n",
       "6         766.628906     {'ridge__alpha': 766.6289057556017}   \n",
       "7          12.852228    {'ridge__alpha': 12.852228299703652}   \n",
       "8           0.768407    {'ridge__alpha': 0.7684071705306554}   \n",
       "9           0.225271   {'ridge__alpha': 0.22527090779355338}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.601302           0.609083           0.611143           0.599832   \n",
       "1           0.600687           0.609405           0.611168           0.600000   \n",
       "2           0.600686           0.609406           0.611168           0.600001   \n",
       "3           0.600772           0.609365           0.611167           0.599981   \n",
       "4           0.601515           0.608953           0.611123           0.599758   \n",
       "5           0.600699           0.609399           0.611168           0.599997   \n",
       "6           0.595454           0.581754           0.592100           0.575095   \n",
       "7           0.601215           0.609133           0.611150           0.599860   \n",
       "8           0.600718           0.609391           0.611168           0.599993   \n",
       "9           0.600694           0.609402           0.611168           0.599999   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0          -0.014181         0.481436        0.247846                8  \n",
       "1          -0.012443         0.481763        0.247144                2  \n",
       "2          -0.012440         0.481764        0.247143                1  \n",
       "3          -0.012674         0.481722        0.247239                6  \n",
       "4          -0.014821         0.481306        0.248101                9  \n",
       "5          -0.012477         0.481757        0.247158                4  \n",
       "6          -0.052151         0.458450        0.255404               10  \n",
       "7          -0.013925         0.481486        0.247744                7  \n",
       "8          -0.012527         0.481749        0.247178                5  \n",
       "9          -0.012463         0.481760        0.247152                3  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    make_pipeline(std_scl, Ridge()), param_distributions=param_dist, n_jobs=-1, random_state=123, scoring='r2',\n",
    ")\n",
    "random_search.fit(X_train, y_train);\n",
    "cv_result = pd.DataFrame(random_search.cv_results_)\n",
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4817436794567209"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics[\"Ridge\"]['test_r2'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4817640543326786"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result.loc[np.argmin(cv_result['rank_test_score']), 'mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0374875957684946e-05"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result.loc[np.argmin(cv_result['rank_test_score']), 'mean_test_score'] - evaluation_metrics[\"Ridge\"]['test_r2'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the best scoring model is only ever slightly better compared to the default values, and some of the models perform poorer than the default `alpha=1.0` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.5 Test results\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try the best model on the test set.\n",
    "2. Briefly comment on the results. (1 to 2 sentences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8129395782451326"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = pipelines['Random Forest']\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.498754043116472"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.322965889799463"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to perform well with a reasonably high $R^2$, and reasonably small MAPE and root mean squared error. With only 8 features, it could be difficult to significantly improve upon the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Model interpretation  \n",
    "rubric={points:4}\n",
    "\n",
    "Ridge is a linear model and it learns coefficients associated with each feature during `fit()`. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Visualize coefficients learned by the `Ridge` model above as a pandas dataframe with two columns: features and coefficients. If you attempted 3.4, use the `Ridge` model with best hyperparameters. Otherwise use the `Ridge` model with default hyperparameters. \n",
    "2. Increasing which feature values would result in higher housing price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MedInc</td>\n",
       "      <td>0.836009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AveBedrms</td>\n",
       "      <td>0.318284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HouseAge</td>\n",
       "      <td>0.115223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Population</td>\n",
       "      <td>-0.007403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AveOccup</td>\n",
       "      <td>-0.041683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AveRooms</td>\n",
       "      <td>-0.281897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>-0.855532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>-0.890132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     features  coefficients\n",
       "0      MedInc      0.836009\n",
       "3   AveBedrms      0.318284\n",
       "1    HouseAge      0.115223\n",
       "4  Population     -0.007403\n",
       "5    AveOccup     -0.041683\n",
       "2    AveRooms     -0.281897\n",
       "7   Longitude     -0.855532\n",
       "6    Latitude     -0.890132"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From Lectue 10\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"features\": std_scl.get_feature_names_out(),\n",
    "        \"coefficients\": random_search.best_estimator_.named_steps[\"ridge\"].coef_,\n",
    "    }\n",
    ")\n",
    "\n",
    "df.sort_values(\"coefficients\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing `MedInc`, `AveBedrms`, and/or `HouseAge` would result in higher housing price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "name": "_merged",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "438px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
